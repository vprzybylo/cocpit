{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "#from comet_ml import Experiment\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import time\n",
    "import copy\n",
    "from shutil import copyfile\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from logger import Logger\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### equal pull from classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights_for_balanced_classes(train_imgs, nclasses):   \n",
    "    #only weight training dataset \n",
    "    \n",
    "    class_sample_counts = [0] * nclasses                                                      \n",
    "    for item in train_imgs:  \n",
    "        class_sample_counts[item[1]] += 1      \n",
    "    print('counts per class: ', class_sample_counts)\n",
    "#     weight_per_class = [0.] * nclasses                                      \n",
    "#     N = float(sum(class_sample_counts))                                                   \n",
    "#     for i in range(nclasses): \n",
    "#         weight_per_class[i] = N/float(class_sample_counts[i])                                 \n",
    "#     weight = [0] * len(images)                                              \n",
    "#     for idx, val in enumerate(images):    \n",
    "#         weight[idx] = weight_per_class[val[1]]  \n",
    "        \n",
    "    class_weights = 1./torch.Tensor(class_sample_counts)\n",
    "    train_targets = [sample[1] for sample in train_imgs]\n",
    "    train_samples_weights = [class_weights[class_id] for class_id in train_targets]\n",
    "\n",
    "    return torch.DoubleTensor(train_samples_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_val(class_names, datadir, batch_size, show_sample=True, num_workers=32, valid_size = .8):\n",
    "    \n",
    "    all_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "    all_data_wpath = ImageFolderWithPaths(datadir,transform=all_transforms) #custom dataset that includes entire path\n",
    "    \n",
    "    \n",
    "#     num_train = len(all_data_wpath)\n",
    "#     indices = list(range(num_train))\n",
    "#     split = int(np.floor(valid_size * num_train))\n",
    "#     np.random.shuffle(indices)\n",
    "#     train_idx, val_idx = indices[split:], indices[:split-1]\n",
    "    \n",
    "#     train_data = torch.utils.data.Subset(all_data_wpath, train_idx)\n",
    "#     val_data = torch.utils.data.Subset(all_data_wpath, val_idx)\n",
    "    \n",
    "    train_length = int(valid_size* len(all_data_wpath))\n",
    "    val_length = len(all_data_wpath)-train_length\n",
    "    train_data, val_data = torch.utils.data.random_split(all_data_wpath,(train_length,val_length))\n",
    "    #print(len(train_data), len(val_data))\n",
    "    \n",
    "    # For an unbalanced dataset we create a weighted sampler                       \n",
    "    train_samples_weights = make_weights_for_balanced_classes(train_data.dataset.imgs, len(range(num_classes)))                                                                   \n",
    "    \n",
    "    train_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_samples_weights, \n",
    "                                                                   len(train_samples_weights),\n",
    "                                                                   replacement=True)                     \n",
    "    trainloader = torch.utils.data.DataLoader(train_data.dataset, batch_size=batch_size,                              \n",
    "                                            sampler = train_sampler, num_workers=num_workers, pin_memory=True)    \n",
    "    \n",
    "    val_sampler = SubsetRandomSampler(val_data.indices)                 \n",
    "    valloader = torch.utils.data.DataLoader(val_data.dataset, batch_size=batch_size,                             \n",
    "                                            sampler = val_sampler, num_workers=num_workers, pin_memory=True)  \n",
    "\n",
    "#     val_samples_weights = make_weights_for_balanced_classes(val_data.dataset.imgs, len(range(num_classes)))                                                                   \n",
    "    \n",
    "#     val_sampler = torch.utils.data.sampler.WeightedRandomSampler(val_samples_weights, \n",
    "#                                                                    len(val_samples_weights),\n",
    "#                                                                    replacement=True)                     \n",
    "#     valloader = torch.utils.data.DataLoader(val_data.dataset, batch_size=batch_size,                              \n",
    "#                                             sampler = val_sampler, num_workers=num_workers, pin_memory=True)    \n",
    "    \n",
    "    if show_sample:\n",
    "        show_sample(train_data, train_sampler)\n",
    "            \n",
    "    return trainloader, valloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(train_data, train_sampler):\n",
    "    \n",
    "    batch_size_sampler=20\n",
    "    sample_loader = torch.utils.data.DataLoader(train_data.dataset, batch_size=batch_size_sampler, \\\n",
    "                                                sampler = train_sampler, num_workers=1, drop_last=True)\n",
    "\n",
    "    data_iter = iter(sample_loader)\n",
    "\n",
    "    images, labels, paths = data_iter.next()\n",
    "    fig, ax = plt.subplots(batch_size_sampler//5, 5, figsize=(10, 8))\n",
    "\n",
    "    for j in range(images.size()[0]):\n",
    "        \n",
    "        # Undo preprocessing\n",
    "        image = images[j].permute(1, 2, 0).cpu().numpy()\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "        image = std * image + mean\n",
    "\n",
    "        # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "        image = np.clip(image, 0, 1)\n",
    "        ax = ax.flatten()\n",
    "        ax[j].set_title(str(class_names[labels[j]]))\n",
    "        ax[j].axis('off') \n",
    "        ax[j].imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_loader(datadir,\n",
    "                    batch_size,\n",
    "                    num_workers,\n",
    "                    shuffle=True,\n",
    "                    pin_memory=True):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning a multi-process\n",
    "    test iterator \n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "    Params\n",
    "    ------\n",
    "    - data_dir: path directory to the dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - shuffle: whether to shuffle the dataset after every epoch.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "    Returns\n",
    "    -------\n",
    "    - data_loader: test set iterator.\n",
    "    \"\"\"\n",
    "    transforms_ = transforms.Compose([transforms.Resize(224),  #resizing helps memory usage\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "    all_data_wpath = ImageFolderWithPaths(datadir,transform=transforms_)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(all_data_wpath,pin_memory=True,shuffle=shuffle,\n",
    "                    batch_size=batch_size, num_workers=num_workers)  \n",
    "\n",
    "    return testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "def set_parameter_requires_grad(model, feature_extract):\n",
    "    if feature_extract:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=False):\n",
    "\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    # variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        #mlp = nn.DataParallel(linear)\n",
    "        #mlp(torch.zeros((32, 100)))\n",
    "        \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg19_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorboard_logging(logger, loss, acc, step, model): \n",
    "    \n",
    "    # 1. Log scalar values (scalar summary)\n",
    "    info = { 'loss': loss, 'accuracy': acc}\n",
    "\n",
    "    for tag, value in info.items():\n",
    "        logger.scalar_summary(tag, value, step+1)\n",
    "\n",
    "    # 2. Log values and gradients of the parameters (histogram summary)\n",
    "    for tag, value in model.named_parameters():\n",
    "        tag = tag.replace('.', '/')\n",
    "        logger.histo_summary(tag, value.data.cpu().numpy(), step+1)\n",
    "        logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step+1)\n",
    "\n",
    "    # 3. Log training images (image summary)\n",
    "    #         denormalize = transforms.Normalize((-1,), (1 / 0.5,))\n",
    "    #         info = { 'images': demormalize(images)[:10].cpu().numpy() }\n",
    "\n",
    "    #         for tag, images in info.items():\n",
    "    #             logger.image_summary(tag, images, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, savename, dataloaders_dict, epochs, num_classes, is_inception, feature_extract=False):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    logger_train = Logger('./logs/'+current_time+'/train/')\n",
    "    logger_val = Logger('./logs/'+current_time+'/val/')\n",
    "    model, input_size = initialize_model(model_name=model_name, num_classes=num_classes, feature_extract=feature_extract, use_pretrained=False)\n",
    "    \n",
    "    def set_dropout(model, drop_rate=0.1):\n",
    "        for name, child in model.named_children():\n",
    "            \n",
    "            if isinstance(child, torch.nn.Dropout):\n",
    "                child.p = drop_rate\n",
    "            set_dropout(child, drop_rate=drop_rate)\n",
    "    set_dropout(model, drop_rate=0.0)\n",
    "    print(model)\n",
    "    \n",
    "#     model.classifier = nn.Sequential(*[model.classifier()[i] for i in range(7) if i != 2 and i !=5])\n",
    "#     print(model.classifier())\n",
    "\n",
    "    #feature extract False for all layers to be updated\n",
    "   \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Send the model to GPU\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Gather the parameters to be optimized/updated in this run. If we are\n",
    "    #  finetuning we will be updating all parameters. However, if we are\n",
    "    #  doing feature extract method, we will only update the parameters\n",
    "    #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "    #  is True.\n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        \n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                #print(\"\\t\",name)\n",
    "    #else:\n",
    "        #for name,param in model.named_parameters():\n",
    "            #if param.requires_grad == True:\n",
    "                #print(\"\\t\",name)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "    # step_size: at how many multiples of epoch you decay\n",
    "    # step_size = 1, after every 1 epoch, new_lr = lr*gamma \n",
    "    # step_size = 2, after every 2 epoch, new_lr = lr*gamma \n",
    "    # gamma = decaying factor\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "    \n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=0, verbose=True, eps=1e-05)\n",
    "\n",
    "    # Setup the loss fxn\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "     \n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    train_loss_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc_val = 0.0\n",
    "    since_total = time.time()\n",
    "    \n",
    "    step = 0\n",
    "    label_counts = [0]*len(range(num_classes))\n",
    "    for epoch in range(epochs):\n",
    "        since_epoch = time.time()\n",
    "        #print('Epoch {}/{}'.format(epoch+1,num_epochs))\n",
    "        print('-' * 20)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            print('Phase: {}'.format(phase))\n",
    "            totals_train = 0\n",
    "            totals_val = 0\n",
    "            running_loss_train = 0.0\n",
    "            running_loss_val = 0.0\n",
    "            running_corrects_train = 0\n",
    "            running_corrects_val = 0\n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train() \n",
    "                logger = logger_train\n",
    "            else:\n",
    "                model.eval()   \n",
    "                logger = logger_val\n",
    "            \n",
    "            \n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels, paths) in enumerate(dataloaders_dict[phase]):\n",
    "                #print(i)\n",
    "                \n",
    "                for n in range(len(range(num_classes))):\n",
    "                    label_counts[n] += len(np.where(labels.numpy() == n)[0])\n",
    "                    \n",
    "#                 for n in range(len(range(num_classes))):\n",
    "#                     print(\"batch index {}, {} counts: {}\".format(\n",
    "#                         i, n, (labels == n).sum()))\n",
    "\n",
    "                \n",
    "#                print('LABEL COUNT = ', label_counts)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                #print(inputs.device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad() # a clean up step for PyTorch\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # makes sure to clear the intermediate values for evaluation\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward() # compute updates for each parameter\n",
    "                        optimizer.step() # make the updates for each parameter                        \n",
    "\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    #Batch accuracy and loss statistics   \n",
    "                    batch_loss_train = loss.item() * inputs.size(0)     \n",
    "                    batch_corrects_train = torch.sum(preds == labels.data) \n",
    "                    #tensorboard_logging(logger, batch_loss_train, labels, batch_corrects_train, step, model)\n",
    "                    \n",
    "                    #for accuracy and loss statistics overall \n",
    "                    running_loss_train += loss.item() * inputs.size(0)\n",
    "                    running_corrects_train += torch.sum(preds == labels.data)\n",
    "                    totals_train += labels.size(0)\n",
    "                    \n",
    "                    if (i+1) % 5 == 0:\n",
    "                        print(\"Training, Batch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(i+1,\\\n",
    "                                                                      len(dataloaders_dict[phase]), \\\n",
    "                                                                      batch_loss_train/labels.size(0), \\\n",
    "                                                                      float(batch_corrects_train)/labels.size(0)))\n",
    "                    step += 1\n",
    "                    \n",
    "                else:\n",
    "                    #Batch accuracy and loss statistics  \n",
    "                    batch_loss_val = loss.item() * inputs.size(0)     \n",
    "                    batch_corrects_val = torch.sum(preds == labels.data) \n",
    "                    \n",
    "                    \n",
    "                    #for accuracy and loss statistics overall\n",
    "                    running_loss_val += loss.item() * inputs.size(0)\n",
    "                    running_corrects_val += torch.sum(preds == labels.data)\n",
    "                    totals_val += labels.size(0)\n",
    "                    \n",
    "                    if (i+1) % 3 == 0:\n",
    "                        print(\"Validation, Batch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(i+1,\\\n",
    "                                                                      len(dataloaders_dict[phase]), \\\n",
    "                                                                      batch_loss_val/labels.size(0), \\\n",
    "                                                                      float(batch_corrects_val)/labels.size(0)))\n",
    "\n",
    "            if phase == 'train':\n",
    "                #epoch loss and accuracy stats    \n",
    "                epoch_loss_train = running_loss_train / totals_train\n",
    "                epoch_acc_train = running_corrects_train.double() / totals_train\n",
    "                scheduler.step(epoch_acc_train) #reduce learning rate if not improving acc\n",
    "                print(\"Training Epoch {}/{}, Loss: {:.3f}, Accuracy: \\033[1m {:.3f} \\033[0m\".format(epoch+1,epochs, epoch_loss_train, epoch_acc_train))\n",
    "                #tensorboard_logging(logger, epoch_loss_train, epoch_acc_train, epoch, model)\n",
    "                train_acc_history.append(epoch_acc_train)\n",
    "                train_loss_history.append(epoch_loss_train)\n",
    "            else: \n",
    "                epoch_loss_val = running_loss_val / totals_val\n",
    "                epoch_acc_val = running_corrects_val.double() / totals_val\n",
    "                scheduler.step(epoch_acc_val) #reduce learning rate if not improving acc\n",
    "                print(\"Validation Epoch {}/{}, Loss: {:.3f}, Accuracy: \\033[1m {:.3f} \\033[0m\".format(epoch+1,epochs, epoch_loss_val, epoch_acc_val))\n",
    "                #tensorboard_logging(logger, epoch_loss_val, epoch_acc_val, epoch, model)\n",
    "                val_acc_history.append(epoch_acc_val)\n",
    "                val_loss_history.append(epoch_loss_val)\n",
    "                \n",
    "                #deep copy the model\n",
    "                if epoch_acc_val > best_acc_val:\n",
    "                    best_acc_val = epoch_acc_val\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    # save/load best model weights\n",
    "                    torch.save(model, savename)\n",
    "\n",
    "        time_elapsed = time.time() - since_epoch\n",
    "        print('Epoch complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    time_elapsed = time.time() - since_total\n",
    "    print('All epochs comlete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return model, train_acc_history, val_acc_history, train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    for batch_size in params['batch_size']:\n",
    "        print('NEW BATCH SIZE: ', batch_size) \n",
    "        train_loader, val_loader = load_split_train_val(\n",
    "            class_names=class_names, \n",
    "            datadir=data_dir,\n",
    "            batch_size=batch_size,\n",
    "            show_sample=False,\n",
    "            num_workers=num_workers)\n",
    "\n",
    "        dataloaders_dict = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "        model_train_accs = []\n",
    "        model_val_accs = []  \n",
    "        model_train_loss = []\n",
    "        model_val_loss = []\n",
    "        for model_name in params['model_names']:  #only resnet \n",
    "            for epochs in params['max_epochs']:\n",
    "                model_ft, train_acc_history, val_acc_history, train_loss_history, val_loss_history= train_model(\n",
    "                    model_name,\n",
    "                    params['savename'],\n",
    "                    dataloaders_dict,\n",
    "                    epochs, \n",
    "                    num_classes,\n",
    "                    is_inception=False\n",
    "                )\n",
    "                \n",
    "                model_val_accs.append(val_acc_history)\n",
    "                model_train_accs.append(train_acc_history)\n",
    "                model_train_loss.append(train_loss_history)\n",
    "                model_val_loss.append(val_loss_history)\n",
    "                \n",
    "    return model_name, model_train_accs, model_val_accs, model_train_loss, model_val_loss, train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    params = {'lr': [0.01],\n",
    "          'batch_size': [512],\n",
    "          'max_epochs': [40],\n",
    "          'optimizer':[torch.optim.Adam, torch.optim.Adagrad, torch.optim.Adadelta, torch.optim.Adamax],\n",
    "          'momentum': [0.9, 0.999], #fixed right now\n",
    "          'model_names':['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet'],\n",
    "          'savename': 'save_models/512_40_all_drop0.0'}\n",
    "    #model_names = ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet', 'inception']\n",
    "\n",
    "    data_dir = 'cpi_data/OLYMPEX/nopad/'\n",
    "    num_workers = 20  #change to # of cores available to load images\n",
    "    class_names=['aggregate', 'blurry', 'column', 'fragment', 'rimed aggregate', 'rimed column', 'sphere']\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    model_name, model_train_accs, model_val_accs, model_train_loss, model_val_loss, train_loader, val_loader = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACCURACY PLOT for training and validation\n",
    "fig = plt.figure(figsize=(9,5))\n",
    "num_epochs = 50\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i.cpu().numpy()*100 for i in model_train_accs[0]], label='train')\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i.cpu().numpy()*100 for i in model_val_accs[0]], label='validation')\n",
    " \n",
    "plt.legend()\n",
    "plt.xticks(np.arange(1, (num_epochs+1), 10.0))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy [%]\")\n",
    "\n",
    "\n",
    "#LOSS PLOT for training and validation\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i for i in model_train_loss[0]], label='train')\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i for i in model_val_loss[0]], label='validation')\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(1, (num_epochs+1), 10.0))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACCURACY PLOT for training and validation\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "num_epochs = 50\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i.cpu().numpy()*100 for i in model_train_accs[0]], label='train')\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i.cpu().numpy()*100 for i in model_val_accs[0]], label='validation')\n",
    "plt.ylim((90.0,100.))  \n",
    "plt.legend()\n",
    "plt.xticks(np.arange(1, (num_epochs+1), 10.0))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy [%]\")\n",
    "\n",
    "\n",
    "#LOSS PLOT for training and validation\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i for i in model_train_loss[0]], label='train')\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i for i in model_val_loss[0]], label='validation')\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(1, (num_epochs+1), 10.0))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACCURACY PLOT for training and validation\n",
    "fig = plt.figure(figsize=(9,5))\n",
    "num_epochs = 15\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i.cpu().numpy()*100 for i in model_train_accs[0]], label='train')\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i.cpu().numpy()*100 for i in model_val_accs[0]], label='validation')\n",
    "plt.ylim((0.0,100.))  \n",
    "plt.legend()\n",
    "plt.xticks(np.arange(1, (num_epochs+1), 1.0))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy [%]\")\n",
    "\n",
    "\n",
    "#LOSS PLOT for training and validation\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i for i in model_train_loss[0]], label='train')\n",
    "plt.plot(np.arange(1,(num_epochs+1)),[i for i in model_val_loss[0]], label='validation')\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(1, (num_epochs+1), 1.0))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer learning method\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "num_epochs = 15\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "colors = ['r', 'b', 'g', 'c', 'k']\n",
    "model_names = ['resnet50', 'alexnet', 'vgg11_bn', 'squeezenet1_0', 'densenet121']\n",
    "for i, (model,train_accs,val_accs) in enumerate(zip(model_names, model_train_accs, model_val_accs)):\n",
    "    plt.plot(np.arange(1,(num_epochs+1)), [i.cpu().numpy()*100 for i in train_accs[:num_epochs]], colors[i], linestyle='--')\n",
    "    plt.plot(np.arange(1,(num_epochs+1)), [i.cpu().numpy()*100 for i in val_accs[:num_epochs]], colors[i], linestyle='-', label=str(model))\n",
    "plt.ylim(0,100)\n",
    "plt.xlim(1,num_epochs)\n",
    "plt.legend(title='Model type:', loc='right', prop={'size': 10})\n",
    "plt.xticks(np.arange(1, num_epochs+1, 2.0))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "for i, (model,train_loss, val_loss) in enumerate(zip(model_names, model_train_loss, model_val_loss)):\n",
    "    plt.plot(np.arange(1,(num_epochs+1)), [i for i in train_loss[:num_epochs]], colors[i], linestyle='--')\n",
    "    plt.plot(np.arange(1,(num_epochs+1)), [i for i in val_loss[:num_epochs]], colors[i], linestyle='-',label=str(model))\n",
    "plt.legend(title='Model type:', loc='right', prop={'size': 10})\n",
    "plt.ylim(0,2.4)\n",
    "plt.xlim(1,num_epochs)\n",
    "plt.xticks(np.arange(1, num_epochs+1, 2))\n",
    "plt.tight_layout()\n",
    "fig.savefig('cpi_data/OLYMPEX/plots/loss_acc_allmodels_reducelr_all_512_0dp.eps')\n",
    "fig.savefig('cpi_data/OLYMPEX/plots/loss_acc_allmodels_reducelr_all_512_0dp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "for model,accs in zip(model_names, model_val_accs):\n",
    "    plt.scatter(np.arange(1,(num_epochs+1)/2),accs, label=str(model))\n",
    "plt.ylim((0.8,1.))\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, class_names, dataloaders, num_images=8):\n",
    "    #subplots with title as right or wrong prediction\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_handeled = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_handeled += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_handeled)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                inputs_show = inputs[j].permute(1, 2, 0)\n",
    "                plt.imshow(inputs_show.cpu().numpy())\n",
    "\n",
    "                if images_handeled == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft, class_names, dataloaders=dataloaders_dict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(len(class_names)))\n",
    "class_total = list(0. for i in range(len(class_names)))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels, _ = data\n",
    "        #images = Variable(images)\n",
    "        #labels = Variable(labels)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_ft(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(class_names)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    print('Accuracy of %5s : %2f %%' % (\n",
    "        class_names[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove predictions that are wrong to clean up the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_ft = model_ft.to(device)\n",
    "class_names=['agg','column','junk','rimed_agg', 'rimed_column', 'spheres']\n",
    "wrong_preds = []\n",
    "for batch_idx, (imgs, labels, paths) in enumerate(dataloaders_dict['train']):\n",
    "\n",
    "    #make a prediction on each batch \n",
    "    input = Variable(imgs)\n",
    "    input = input.to(device)\n",
    "    predictions = model_ft(input)\n",
    "    preds = torch.max(predictions, 1).indices.tolist()    \n",
    "    labels = labels.cpu().numpy().tolist()\n",
    "\n",
    "    for (file, im, la, pred) in zip(paths, imgs, labels, preds):\n",
    "        \n",
    "        if class_names[pred] != class_names[la]: \n",
    "            inputs_show = im.permute(1, 2, 0)\n",
    "            #plt.imshow(inputs_show.cpu().numpy())\n",
    "            #plt.title('predicted: ' + str(class_names[pred]) + ' labeled: ' +str(class_names[la]))\n",
    "            #plt.show()\n",
    "\n",
    "            try:\n",
    "                #print('removing'+file)\n",
    "                os.remove(file)\n",
    "                wrong_preds.append(file)\n",
    "            except FileNotFoundError as not_found:\n",
    "                print('in except')\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_agg = 0\n",
    "bad_col = 0\n",
    "bad_rimed_col = 0\n",
    "bad_rimed_agg = 0\n",
    "bad_junk = 0\n",
    "bad_spheres = 0\n",
    "for file in wrong_preds:\n",
    "    if 'aggs' in file:\n",
    "        bad_agg+=1\n",
    "    if 'junk' in file:\n",
    "        bad_junk+=1\n",
    "    if 'columns' in file:\n",
    "        bad_col+=1\n",
    "    if 'rimed_columns' in file:\n",
    "        bad_rimed_col+=1\n",
    "    if 'spheres' in file:\n",
    "        bad_spheres+=1\n",
    "    if 'rimed_agg' in file:\n",
    "        bad_rimed_agg+=1\n",
    "print('bad aggs {}, bad col {}, bad rimed col {}, bad junk {}, bad spheres {}, bad rimed agg {}'\\\n",
    "      .format(bad_agg, bad_col, bad_rimed_col, bad_junk, bad_spheres, bad_rimed_agg))\n",
    "print()\n",
    "\n",
    "#change remove to each category total files\n",
    "print('%.3f %.3f %.3f %.3f %.3f %.3f' %(bad_agg/remove, bad_col/remove, \\\n",
    "      bad_rimed_col/remove, bad_rimed_agg/remove, bad_junk/remove, bad_spheres/remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model on the data that has been qc'ed and have it compute gradients on all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the model for this run\n",
    "model_val_accs_qc = []\n",
    "\n",
    "for model in model_names:\n",
    "     = Falsefeature_extract\n",
    "    model_ft, input_size = initialize_model(model, num_classes, feature_extract, use_pretrained=True)\n",
    "    \n",
    "    #if torch.cuda.device_count() > 1:\n",
    "    #    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    #    model_ft = nn.DataParallel(model)\n",
    "    model_ft = model_ft.to(device)\n",
    "    \n",
    "    # Gather the parameters to be optimized/updated in this run. If we are\n",
    "    #  finetuning we will be updating all parameters. However, if we are\n",
    "    #  doing feature extract method, we will only update the parameters\n",
    "    #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "    #  is True.\n",
    "    params_to_update = model_ft.parameters()\n",
    "        \n",
    "    print(\"Params to learn:\")\n",
    "    \n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Print the model we just instantiated\n",
    "    #print(model_ft)\n",
    "    # Setup the loss fxn\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train and evaluate\n",
    "    \n",
    "    model_ft, val_acc_qc = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model==\"inception\"))\n",
    "    model_val_accs_qc.append(val_acc_qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "for model,accs in zip(model_names, model_val_accs_qc):\n",
    "    plt.scatter(range(1,num_epochs+1),accs, label=str(model))\n",
    "plt.ylim((0.8,1.))\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = preprocess(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(image_path, model, topk=6):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert('RGB')\n",
    "    img = process_image(img)\n",
    "    \n",
    "    # Convert 2D image to 1D vector\n",
    "    img = np.expand_dims(img, 0)\n",
    "    \n",
    "    \n",
    "    img = torch.from_numpy(img)\n",
    "    \n",
    "    model.eval()\n",
    "    inputs = Variable(img).to(device)\n",
    "    logits = model.forward(inputs)\n",
    "    \n",
    "    ps = F.softmax(logits,dim=1)\n",
    "    topk = ps.cpu().topk(topk)\n",
    "    \n",
    "    return (e.data.numpy().squeeze().tolist() for e in topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img_path, prob, classes, crystal_names):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    image = Image.open(img_path)\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(7, 10), ncols=1, nrows=2)\n",
    "    \n",
    "    ax1.set_title(crystal_names[0])\n",
    "    ax1.imshow(image)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    y_pos = np.arange(len(prob))\n",
    "    ax2.barh(y_pos, prob, align='center')\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(crystal_names)\n",
    "    ax2.tick_params(axis='y', rotation=45)\n",
    "    ax2.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax2.set_title('Class Probability')\n",
    "    plt.show()\n",
    "    current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    fig.savefig('classify/'+current_time+'.png',bbox_inches='tight',pad_inches=.3)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class_names=['aggregate','blurry','columns','fragment','rimed_aggs', 'rimed_columns', 'spheres']\n",
    "nb_classes = len(class_names)\n",
    "data_dir = 'cpi_data/OLYMPEX/nopad/'\n",
    "model = torch.load('save_models/512_50_vgg19_bn_drop0.0')\n",
    "#model_ft.load_state_dict(best_model_wts)\n",
    "num_classes = 7\n",
    "model_name = 'vgg'\n",
    "batch_size = 512\n",
    "num_epochs = 10\n",
    "num_workers = 20\n",
    "\n",
    "train_loader, val_loader = load_split_train_val(\n",
    "            class_names=class_names, \n",
    "            datadir=data_dir,\n",
    "            batch_size=batch_size,\n",
    "            show_sample=False,\n",
    "            num_workers=num_workers)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Send the model to GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "    #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "for batch_idx, (imgs, labels, img_paths) in enumerate(val_loader):\n",
    "    #predictions = model_ft(imgs)\n",
    "    #preds = torch.max(predictions, 1).indices.tolist()    \n",
    "    \n",
    "    for im in img_paths:\n",
    "        \n",
    "        probs, classes = predict2(im, model.to(device))  \n",
    "        crystal_names = [class_names[e] for e in classes]\n",
    "\n",
    "        #if classes[0] != 3 and classes[0] != 1 and classes[0] != 2:\n",
    "        view_classify(im, probs, classes, crystal_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('save_models/512_50_vgg19_bn_drop0.0').cuda()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, val_loader = load_split_train_val(\n",
    "            class_names=class_names, \n",
    "            datadir=data_dir,\n",
    "            batch_size=batch_size,\n",
    "            show_sample=False,\n",
    "            num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(conf_matrix, index = [i for i in class_names],\n",
    "                  columns = [i for i in class_names])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds= []\n",
    "all_labels = []\n",
    "for batch_idx, (imgs, labels, img_paths) in enumerate(val_loader):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch_idx, (imgs, labels, img_paths) in enumerate(val_loader):\n",
    "            # get the inputs\n",
    "            inputs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            output = model(inputs)\n",
    "            pred = torch.argmax(output, 1)\n",
    "            all_preds.append(pred.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "conf_matrix = confusion_matrix(np.asarray(list(itertools.chain(*all_preds))), np.asarray(list(itertools.chain(*all_labels))))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(np.asarray(list(itertools.chain(*all_labels))),np.asarray(list(itertools.chain(*all_preds))))\n",
    "\n",
    "df_cm = pd.DataFrame(conf_matrix, index = [i for i in class_names],\n",
    "                  columns = [i for i in class_names])\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g', cmap=\"Blues\")\n",
    "plt.ylabel('Predicted label')\n",
    "plt.xlabel('Actual label')\n",
    "fig.tight_layout()\n",
    "plt.savefig('cpi_data/OLYMPEX/plots/conf_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(list(itertools.chain(*all_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
