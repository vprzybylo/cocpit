{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import cocpit.config as config\n",
    "import cocpit\n",
    "\n",
    "import ipywidgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_params = {\n",
    "    \"axes.labelsize\": \"xx-large\",\n",
    "    \"axes.titlesize\": \"xx-large\",\n",
    "    \"xtick.labelsize\": \"xx-large\",\n",
    "    \"ytick.labelsize\": \"xx-large\",\n",
    "    \"legend.title_fontsize\": 12,\n",
    "}\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams.update(plt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check classifications from specific model and validation dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(\n",
    "    f\"/data/data/saved_models/no_mask/{config.TAG}/e15_bs64_1model(s).pt\"\n",
    ").cuda()\n",
    "#val_data = torch.load(\n",
    "#    f\"/data/data/saved_val_loaders/no_mask/{config.TAG}/e15_bs64_1model(s).pt\"\n",
    "#)\n",
    "\n",
    "#val_loader = torch.utils.data.DataLoader(\n",
    "#    val_data, batch_size=11, shuffle=True, num_workers=20, pin_memory=True\n",
    "#)\n",
    "data = cocpit.data_loaders.get_data()\n",
    "dataloader = torch.utils.data.DataLoader(data, batch_size=100, num_workers=20, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21965/2552534494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#convert back to lists from being on gpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mmax_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "use the above model and validation dataloader to check predictions\n",
    "loops through all validation loader predictions but only save incorrect predictions\n",
    "the incorrect predictions are loaded into a gui so that a user can decide \n",
    "whether the label was wrong/model was right\n",
    "'''\n",
    "\n",
    "model.eval()\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "top_k_preds = 9  # the top k predictions will be displayed in bar chart\n",
    "\n",
    "all_labels = []\n",
    "all_paths = []\n",
    "all_topk_probs = []\n",
    "all_topk_classes = []\n",
    "all_max_preds = []\n",
    "\n",
    "try:\n",
    "    for batch_idx, ((imgs, labels, paths), index) in enumerate(dataloader):        \n",
    "        imgs = imgs.to(config.DEVICE)\n",
    "        labels = labels.to(config.DEVICE)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        # dimension 1 because taking the prediction\n",
    "        # with the highest probability\n",
    "        # from all classes across each index in the batch\n",
    "        _, max_preds = torch.max(logits, dim = 1)  \n",
    "\n",
    "        #convert back to lists from being on gpus\n",
    "        max_preds = max_preds.cpu().tolist()\n",
    "        labels = labels.cpu().tolist()\n",
    "\n",
    "        wrong_idx = [index for index, elem in enumerate(max_preds)\n",
    "                               if elem != labels[index]]\n",
    "\n",
    "        # make sure there is an incorrect prediction in this batch otherwise skip appending      \n",
    "        if len(wrong_idx)!=0: \n",
    "            # get top k predictions for each index in the batch for bar chart\n",
    "            predictions = F.softmax(logits, dim=1)\n",
    "            topk = predictions.cpu().topk(top_k_preds)  # top k predictions\n",
    "            probs, classes = [e.data.numpy().squeeze().tolist() for e in topk]\n",
    "\n",
    "            # human label and image path\n",
    "            all_labels.append([labels[i] for i in wrong_idx])\n",
    "            all_paths.append([paths[i] for i in wrong_idx])\n",
    "\n",
    "            # model top k predicted  probability and classes per image\n",
    "            all_topk_probs.append([probs[i] for i in wrong_idx])\n",
    "            all_topk_classes.append([classes[i] for i in wrong_idx])\n",
    "\n",
    "            # top predicted class from model\n",
    "            all_max_preds.append([max_preds[i] for i in wrong_idx])\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"There are files in the dataloader that have already moved and cannot be found.\")\n",
    "    print(\"This is likely due to running an old model that has not captured the updated file movement.\")\n",
    "    print(\"Try rerunning the model to update the validation dataloaders.  Stopping prematurely.\")\n",
    "    pass \n",
    "\n",
    "all_labels = np.asarray(list(itertools.chain(*all_labels)))\n",
    "all_paths = np.asarray(list(itertools.chain(*all_paths)))\n",
    "all_topk_probs = np.asarray(list(itertools.chain(*all_topk_probs)))\n",
    "all_topk_classes = np.asarray(list(itertools.chain(*all_topk_classes)))\n",
    "all_max_preds = np.asarray(list(itertools.chain(*all_max_preds)))\n",
    "\n",
    "            \n",
    "print('DONE FINDING INCORRECT PREDICTIONS!')\n",
    "print(f'There are {len(all_labels)} images to check!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''if you stopped the previous cell early because there are\n",
    "so many wrong predictions run this to capture labels up until you stopped waiting'''\n",
    "all_labels = np.asarray(list(itertools.chain(*all_labels)))\n",
    "all_paths = np.asarray(list(itertools.chain(*all_paths)))\n",
    "all_topk_probs = np.asarray(list(itertools.chain(*all_topk_probs)))\n",
    "all_topk_classes = np.asarray(list(itertools.chain(*all_topk_classes)))\n",
    "all_max_preds = np.asarray(list(itertools.chain(*all_max_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86233465e99349a68349d8869d8c2ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Dropdown(description='Category:', options=('agg', 'budding', 'bullets', 'columns', 'câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "code for ipywidget buttons called cocpit/gui.py\n",
    "\n",
    "this cell displays a bar chart of predictions that the model outputs\n",
    "a dropdown menu is available to move the image if you think the model got the label right \n",
    "when you choose an option from the dropdown list, the image will be moved to that category in the training dataset\n",
    "if you don't want to move the image and the human labeled correctly, simply click \"Next\"\n",
    "'''\n",
    "gui = cocpit.gui.GUI(all_labels, all_paths, all_topk_probs, all_topk_classes, all_max_preds)\n",
    "gui.make_buttons()\n",
    "display(ipywidgets.HBox([gui.center, gui.menu, gui.forward]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1340"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
