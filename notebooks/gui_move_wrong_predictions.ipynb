{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ipywidget interface to move incorrect predictions within the validation dataset should they be labeled wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "import itertools\n",
    "\n",
    "\n",
    "import ipywidgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import cocpit\n",
    "from cocpit import config as config\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check classifications from specific model and validation dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE FINDING INCORRECT PREDICTIONS!\n",
      "There are 4308 total images in the dataloader.\n",
      "There are 1767 wrong predictions to check in the dataloader!\n"
     ]
    }
   ],
   "source": [
    "#  Make predictions on each batch of images,\n",
    "#  concatenate the precitions across batches,\n",
    "#  and return the wrong predictions.\n",
    "#  Loops over folds if using k-fold cross validation\n",
    "\n",
    "# sourcery skip: use-itertools-product\n",
    "p = cocpit.predictions.LoaderPredictions()\n",
    "with torch.no_grad():\n",
    "    for fold in range(config.KFOLD+1):\n",
    "        for ((imgs, labels, paths), _) in p.load_val_loader(fold):\n",
    "            b = cocpit.predictions.BatchPredictions(imgs, p.load_model(fold))\n",
    "            b.find_max_preds()\n",
    "            b.top_k_preds(len(config.CLASS_NAMES))\n",
    "            p.append_batch(b, paths, labels)\n",
    "\n",
    "p.concatenate_loader_vars()\n",
    "p.find_wrong_indices()\n",
    "\n",
    "print(\"DONE FINDING INCORRECT PREDICTIONS!\")                \n",
    "print(f\"There are {len(p.labels)} total images in the dataloader.\")\n",
    "print(f\"There are {len(p.wrong_idx)} wrong predictions to check in the dataloader!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 wrong predictions between compact irregular and aggregate\n"
     ]
    }
   ],
   "source": [
    "# to only look between specific categories run this cell\n",
    "label_list = dict(zip(cocpit.config.CLASS_NAMES, np.arange(0, len(cocpit.config.CLASS_NAMES))))\n",
    "\n",
    "# change these two lines to focus on wrong predictions from a specific category\n",
    "# or box within the confusion matrix\n",
    "# makes labeling easier focusing on two at a time\n",
    "human_label = label_list [\"compact irregular\"]\n",
    "model_label = label_list[\"aggregate\"]\n",
    "\n",
    "p.hone_incorrect_predictions(label_list, human_label, model_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6869a15239de4390b9a22ca0028fe285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Output(),)), VBox(children=(Button(description='aggregate', style=ButtonStyle()),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Display a bar chart of model prediction probabilities\n",
    "A dropdown menu is available to move the image to a different category in the training dataset\n",
    "If you don't want to move the image and the human labeled correctly, simply click \"Next\"\n",
    "\"\"\"\n",
    "g = cocpit.gui_wrong.GUI(p.wrong_trunc, p.labels, p.paths, p.topk_probs, p.topk_classes)\n",
    "g.make_buttons()\n",
    "g.align_buttons()\n",
    "g.visualizations()\n",
    "layout=ipywidgets.Layout(display='flex', width='100%', align_items='center')\n",
    "display(ipywidgets.VBox([ipywidgets.Box([g.center]), g.label_btns, g.next_btn], layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear out the incorrect predictions between a specific scenario for human and model label.\n",
    "# If this cell is run after all images have been iterated through, run the second \n",
    "# to last cell again to hone in on a different set of human and model predictions\n",
    "p.wrong_trunc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
